{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
    "# implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c36198a",
   "metadata": {},
   "source": [
    "# Understanding Bayesian Optimization\n",
    "\n",
    "[Bayesian optimization](https://arxiv.org/abs/1012.2599) is a powerful strategy for **finding the extrema of objective functions** that are expensive to evaluate. It is particularly useful when these evaluations are costly, when one does not have access to derivatives, or when the problem is non-convex.\n",
    "\n",
    "- **Objective function**\n",
    "\n",
    "- **Surrogate function**: Bayesian approximation of the objective function that can be sampled efficiently.\n",
    "\n",
    "- **Acquisition function**: Technique by which the posterior is used to select the next sample from the search space.\n",
    "\n",
    "The **Bayesian Optimization algorithm** can be summarized as follows.\n",
    "\n",
    "- 1. Select a sample by optimizing the Acquisition function.\n",
    "\n",
    "- 2. Evaluate the sample with the Objective function.\n",
    "\n",
    "- 3. Update data and, in turn, the Surrogate function.\n",
    "\n",
    "- 4. Go to 1.\n",
    "\n",
    "Based on URL: https://machinelearningmastery.com/what-is-bayesian-optimization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d1a22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sin\n",
    "from math import pi\n",
    "from numpy import arange\n",
    "from numpy import vstack\n",
    "from numpy import argmax, argmin\n",
    "from numpy import asarray\n",
    "from numpy.random import normal\n",
    "from numpy.random import random\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import ExpSineSquared\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from warnings import catch_warnings\n",
    "from warnings import simplefilter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4232ea6b",
   "metadata": {},
   "source": [
    "## Objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5abd4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ideal multimodal function\n",
    "def multimodal(x):\n",
    "    return (x**2 * sin(2*pi*x)**4.0)\n",
    "\n",
    "# objective function\n",
    "def objective(x, noise=0.1):\n",
    "    noise = normal(loc=0, scale=noise)\n",
    "    return multimodal(x) + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30f812f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# line plot of multimodal function\n",
    "def plot_mm():\n",
    "    X_mm = asarray(arange(0, 1, 0.001))\n",
    "    y_mm = asarray([multimodal(x) for x in X_mm])\n",
    "    plt.plot(X_mm, y_mm, color='b', linestyle='dotted', linewidth=1)\n",
    "    return(X_mm, y_mm)\n",
    "    \n",
    "# plot points of data\n",
    "def plot_points(X, y):\n",
    "    plt.scatter(X, y, color='g', marker='.', s=10, label=r\"$f(x)$\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"$x$\")\n",
    "    plt.ylabel(\"$f(x)$\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cbfb41",
   "metadata": {},
   "source": [
    "## Input data and the true maxima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30b99f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "X = random(100)\n",
    "y = asarray([objective(x) for x in X])\n",
    "plot_points(X, y)\n",
    "\n",
    "# plot ideal multimodal function just for fun\n",
    "plot_mm()\n",
    "\n",
    "# find the true optima\n",
    "ix = argmax(y)\n",
    "X_true_max = X[ix]\n",
    "y_true_max = y[ix]\n",
    "print('The true maxima: x=%.3f, y=%.3f' % (X_true_max, y_true_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad26c6f5",
   "metadata": {},
   "source": [
    "## Approximation for the objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c22336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape into rows and cols\n",
    "X = X.reshape(len(X), 1)\n",
    "y = y.reshape(len(y), 1)\n",
    "\n",
    "# define and fit the model\n",
    "model = GaussianProcessRegressor()\n",
    "model.fit(X, y)\n",
    "\n",
    "# approximation for the objective function by surrogate function\n",
    "def surrogate(model, X):\n",
    "    with catch_warnings():\n",
    "        # ignore generated warnings\n",
    "        simplefilter(\"ignore\")      \n",
    "        return model.predict(X, return_std=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed8c738",
   "metadata": {},
   "source": [
    "### Vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd628fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot real observations - multimodal function - surrogate function\n",
    "def plot(X, y, model):   \n",
    "\n",
    "    # scatter plot of inputs and real objective function\n",
    "    plot_points(X, y)\n",
    "\n",
    "    # line plot of multimodal function\n",
    "    X_mm, y_mm = plot_mm()\n",
    "    \n",
    "    # line plot of surrogate function across domain\n",
    "    X_model = X_mm.reshape(len(X_mm), 1)\n",
    "    y_model, _ = surrogate(model, X_model)\n",
    "    plt.plot(X_model, y_model, color='r', linewidth=1)\n",
    "\n",
    "    # find optima\n",
    "    ix = argmax(y_model)\n",
    "    print('The surrogate maxima: x=%.3f, y=%.3f' % (X_model[ix], y_model[ix]))\n",
    "\n",
    "# plot the surrogate function\n",
    "plot(X, y, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a00132",
   "metadata": {},
   "source": [
    "## Perform the optimization process\n",
    "\n",
    "### Acquisition function and its optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfa0063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of improvement acquisition function\n",
    "def acquisition(X, Xsamples, model):\n",
    "\n",
    "    # calculate the best surrogate score found so far\n",
    "    yhat, _ = surrogate(model, X)\n",
    "    best = max(yhat)\n",
    "\n",
    "    # calculate mean and stdev via surrogate function\n",
    "    mu, std = surrogate(model, Xsamples)\n",
    "    mu = mu[0]\n",
    "    \n",
    "    # calculate the probability of improvement\n",
    "    probs = norm.cdf((mu - best) / (std+1E-9))\n",
    "    return probs\n",
    " \n",
    "\n",
    "# optimize the acquisition function\n",
    "def opt_acquisition(X, y, model):\n",
    "\n",
    "    # random search, generate random samples\n",
    "    Xsamples = random(500)\n",
    "    Xsamples = Xsamples.reshape(len(Xsamples), 1)\n",
    "\n",
    "    # calculate the acquisition function for each sample\n",
    "    scores = acquisition(X, Xsamples, model)\n",
    "\n",
    "    # locate the index of the largest scores\n",
    "    ix = argmax(scores)\n",
    "    \n",
    "    return Xsamples[ix, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640c723e",
   "metadata": {},
   "source": [
    "### Optimization process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235eec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    # select the next point to sample\n",
    "    x = opt_acquisition(X, y, model)\n",
    "\n",
    "    # sample the point\n",
    "    actual = objective(x)\n",
    "\n",
    "    # summarize the finding\n",
    "    est, _ = surrogate(model, [[x]])\n",
    "#     print('>x=%.3f, f()=%3f, actual=%.3f' % (x, est, actual))\n",
    "\n",
    "    # add the data to the dataset\n",
    "    X = vstack((X, [[x]]))\n",
    "    y = vstack((y, [[actual]]))\n",
    "    \n",
    "    # update the model\n",
    "    model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af6b064",
   "metadata": {},
   "source": [
    "### Vizualization and the best result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ad68e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all samples and the final surrogate function\n",
    "plot(X, y, model)\n",
    "    \n",
    "# best result\n",
    "ix = argmax(y)\n",
    "print('Best Result: x=%.3f, y=%.3f' % (X[ix], y[ix]))\n",
    "print('The true maxima: x=%.3f, y=%.3f' % (X_true_max, y_true_max))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
